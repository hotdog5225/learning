{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnist分类任务：\n",
    "\n",
    "- 网络基本构建与训练方法，常用函数解析\n",
    "\n",
    "- torch.nn.functional模块\n",
    "\n",
    "- nn.Module模块\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取Mnist数据集\n",
    "- 会自动进行下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T02:35:07.424827Z",
     "start_time": "2024-07-21T02:35:07.422048Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T02:35:07.435044Z",
     "start_time": "2024-07-21T02:35:07.432873Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T02:35:07.624215Z",
     "start_time": "2024-07-21T02:35:07.449711Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "784是mnist数据集每个样本的像素点个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T02:35:07.677994Z",
     "start_time": "2024-07-21T02:35:07.625152Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "pyplot.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/4.png\" alt=\"FAO\" width=\"790\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/5.png\" alt=\"FAO\" width=\"790\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 注意数据需转换成tensor才能参与后续建模训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T02:35:07.690915Z",
     "start_time": "2024-07-21T02:35:07.678535Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
      "torch.Size([50000, 784])\n",
      "tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")\n",
    "n, c = x_train.shape\n",
    "x_train, x_train.shape, y_train.min(), y_train.max()\n",
    "print(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义get_data函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T02:35:07.712519Z",
     "start_time": "2024-07-21T02:35:07.707946Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "bs=64 # batch size\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True) # DataLoader是用来提供batch数据用的\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T02:35:07.716206Z",
     "start_time": "2024-07-21T02:35:07.714486Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义model结构,优化器optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 必须继承nn.Module且在其构造函数中需调用nn.Module的构造函数\n",
    "- 无需写反向传播函数，nn.Module能够利用autograd自动实现反向传播\n",
    "- Module中的可学习参数可以通过named_parameters()或者parameters()返回迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T02:35:07.700068Z",
     "start_time": "2024-07-21T02:35:07.698150Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Mnist_NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(784, 128)\n",
    "        self.hidden2 = nn.Linear(128, 256)\n",
    "        self.hidden3 = nn.Linear(256, 512)\n",
    "        self.out  = nn.Linear(512, 10)\n",
    "\n",
    "    # torch只需要写前向传播, 反向传播是自动实现的\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = F.relu(self.hidden3(x))\n",
    "        x = self.out(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T02:35:07.721024Z",
     "start_time": "2024-07-21T02:35:07.719580Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "def get_model():\n",
    "    model = Mnist_NN()\n",
    "    return model, optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/dropout.png\" alt=\"dropout\" width=\"790\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T02:35:07.702713Z",
     "start_time": "2024-07-21T02:35:07.700753Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist_NN(\n",
      "  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (hidden2): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (hidden3): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (out): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Mnist_NN()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以打印我们定义好名字里的权重和偏置项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T02:35:07.707354Z",
     "start_time": "2024-07-21T02:35:07.703305Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden1.weight Parameter containing:\n",
      "tensor([[ 0.0041,  0.0021,  0.0138,  ..., -0.0121, -0.0220, -0.0047],\n",
      "        [-0.0106, -0.0049,  0.0193,  ...,  0.0214,  0.0272,  0.0002],\n",
      "        [ 0.0141, -0.0138, -0.0261,  ..., -0.0116,  0.0062,  0.0024],\n",
      "        ...,\n",
      "        [-0.0046,  0.0149,  0.0197,  ..., -0.0193,  0.0196, -0.0046],\n",
      "        [ 0.0159, -0.0122, -0.0304,  ...,  0.0142, -0.0257, -0.0124],\n",
      "        [ 0.0279, -0.0305,  0.0152,  ..., -0.0034,  0.0334, -0.0173]],\n",
      "       requires_grad=True) torch.Size([128, 784])\n",
      "hidden1.bias Parameter containing:\n",
      "tensor([ 0.0330,  0.0334, -0.0122, -0.0352, -0.0109, -0.0334, -0.0006,  0.0092,\n",
      "         0.0042,  0.0008,  0.0022,  0.0189, -0.0245,  0.0344,  0.0349, -0.0049,\n",
      "        -0.0344,  0.0310, -0.0024,  0.0292, -0.0029,  0.0143, -0.0250, -0.0109,\n",
      "         0.0300, -0.0141, -0.0290,  0.0173,  0.0333,  0.0045, -0.0237, -0.0008,\n",
      "         0.0313,  0.0224, -0.0110, -0.0136, -0.0111, -0.0024, -0.0183, -0.0116,\n",
      "         0.0136, -0.0276, -0.0275, -0.0090,  0.0240, -0.0050,  0.0186,  0.0334,\n",
      "         0.0238, -0.0266, -0.0295,  0.0227, -0.0011, -0.0007,  0.0218,  0.0212,\n",
      "        -0.0340, -0.0295, -0.0155, -0.0154, -0.0131, -0.0223,  0.0031,  0.0195,\n",
      "         0.0139, -0.0084, -0.0216,  0.0243, -0.0248,  0.0073, -0.0337, -0.0041,\n",
      "        -0.0051, -0.0220, -0.0066,  0.0019,  0.0102,  0.0089,  0.0166, -0.0112,\n",
      "         0.0185,  0.0070,  0.0130,  0.0038, -0.0117,  0.0001, -0.0269, -0.0071,\n",
      "        -0.0097, -0.0344, -0.0275,  0.0159, -0.0278,  0.0044,  0.0340, -0.0023,\n",
      "         0.0226,  0.0175, -0.0213,  0.0212, -0.0179,  0.0087,  0.0162, -0.0355,\n",
      "        -0.0124,  0.0020, -0.0077,  0.0251,  0.0221,  0.0022,  0.0005,  0.0106,\n",
      "         0.0177,  0.0116,  0.0133, -0.0151,  0.0227,  0.0194, -0.0042, -0.0131,\n",
      "        -0.0081,  0.0028,  0.0185,  0.0127, -0.0183,  0.0088,  0.0215, -0.0054],\n",
      "       requires_grad=True) torch.Size([128])\n",
      "hidden2.weight Parameter containing:\n",
      "tensor([[ 0.0669, -0.0586,  0.0649,  ...,  0.0340, -0.0483, -0.0087],\n",
      "        [-0.0030,  0.0578,  0.0617,  ...,  0.0160,  0.0281,  0.0782],\n",
      "        [ 0.0009,  0.0457, -0.0098,  ...,  0.0434, -0.0880, -0.0826],\n",
      "        ...,\n",
      "        [ 0.0828, -0.0258,  0.0665,  ...,  0.0408, -0.0535,  0.0443],\n",
      "        [-0.0671, -0.0877, -0.0138,  ..., -0.0529, -0.0563, -0.0673],\n",
      "        [-0.0049, -0.0236, -0.0527,  ...,  0.0139,  0.0410, -0.0246]],\n",
      "       requires_grad=True) torch.Size([256, 128])\n",
      "hidden2.bias Parameter containing:\n",
      "tensor([ 8.3719e-02, -3.5059e-02,  5.6064e-02, -7.7004e-02,  3.9148e-02,\n",
      "         3.0170e-02, -7.3412e-03,  4.3350e-02, -1.6540e-02,  5.5614e-02,\n",
      "        -2.8744e-02,  9.5790e-04, -6.7478e-02,  2.7889e-02,  2.5894e-02,\n",
      "         5.0203e-02,  4.4127e-02,  2.2294e-02, -5.0344e-02, -4.1030e-03,\n",
      "        -4.7981e-02,  5.9042e-02, -9.1761e-03, -6.3363e-02, -7.6134e-02,\n",
      "        -7.3424e-02, -4.8854e-02,  5.6313e-02, -3.0749e-02,  8.8041e-02,\n",
      "         8.6733e-02,  8.3047e-02, -3.8914e-02, -3.6236e-02,  2.6183e-02,\n",
      "        -1.6350e-02, -1.8693e-02, -2.2770e-02,  1.5477e-02, -3.3610e-02,\n",
      "        -4.1941e-02, -7.2035e-02,  3.6694e-02,  2.7150e-02, -1.5253e-02,\n",
      "         3.3525e-02, -8.1825e-02,  1.6526e-02,  7.2390e-02, -1.5048e-02,\n",
      "        -4.8173e-02, -1.1224e-02, -7.6780e-02, -2.5721e-04, -8.2116e-02,\n",
      "         4.1668e-02, -4.0995e-02,  7.9318e-02, -8.5081e-02,  6.2181e-02,\n",
      "        -3.3729e-02,  8.3179e-02, -3.3423e-02, -4.5113e-02,  3.6188e-02,\n",
      "        -5.4585e-02, -3.4514e-02,  3.9420e-02,  9.5903e-03,  6.0815e-02,\n",
      "         8.3542e-02, -4.7157e-02,  4.7824e-02,  3.9980e-03,  1.7014e-03,\n",
      "        -1.6116e-02,  2.8855e-02, -3.9968e-02, -7.3684e-02,  5.5965e-02,\n",
      "         3.8363e-02,  3.5685e-02, -2.9064e-02, -6.5632e-02, -5.0157e-02,\n",
      "        -8.4075e-02, -8.1013e-02,  3.4531e-02, -7.1248e-02,  3.0121e-02,\n",
      "        -4.7244e-02, -8.2777e-02, -1.9745e-02, -6.5854e-02,  6.3915e-02,\n",
      "         8.1438e-03,  5.2423e-02,  5.2471e-02,  2.2207e-02,  4.5355e-03,\n",
      "         3.8880e-05, -4.1170e-02, -1.4885e-02,  2.2165e-03,  8.2972e-02,\n",
      "         2.0930e-02, -3.8689e-03,  7.1237e-02, -5.6531e-02,  4.5447e-02,\n",
      "        -7.2022e-03, -1.6451e-02, -8.6260e-02, -4.9624e-02,  6.3398e-02,\n",
      "         7.2704e-02, -5.7105e-02, -9.9171e-03, -7.1699e-03, -6.3620e-02,\n",
      "        -2.4325e-02, -2.7582e-02, -3.5755e-02, -4.9267e-02,  7.2714e-02,\n",
      "         6.5619e-02, -3.5760e-02,  6.6216e-02, -5.6570e-03,  7.5625e-02,\n",
      "         7.4976e-02, -3.9739e-02,  1.8480e-02, -5.8745e-02, -6.5694e-02,\n",
      "         8.0802e-02, -4.4528e-02, -3.0923e-02,  5.1476e-02, -4.8543e-02,\n",
      "         7.9902e-02, -1.5951e-02, -7.6545e-02,  3.9788e-02, -3.9587e-02,\n",
      "         8.8021e-02, -5.4141e-02,  6.5198e-02, -6.1751e-02, -3.6415e-02,\n",
      "         9.2773e-03,  5.1142e-02, -2.9497e-02,  5.9846e-02, -3.0554e-03,\n",
      "        -7.9859e-02, -1.9233e-02, -7.3285e-02, -1.1100e-02,  5.0413e-02,\n",
      "        -4.6536e-02, -9.8698e-03,  7.2273e-02,  6.7500e-02, -7.4124e-03,\n",
      "        -6.3781e-02,  9.7434e-03, -1.0015e-02, -1.7520e-02, -7.7417e-02,\n",
      "        -8.3245e-02,  8.1851e-02, -7.9930e-02, -2.0408e-02,  1.8648e-02,\n",
      "         6.9755e-02, -2.9099e-02, -1.4979e-02,  4.7031e-02, -4.8790e-02,\n",
      "         5.0129e-02,  3.2472e-02,  4.7542e-02, -1.4390e-02, -8.8153e-02,\n",
      "         6.5154e-03,  5.6407e-02,  2.6204e-02,  1.5611e-02,  1.8770e-03,\n",
      "         6.3860e-02,  1.0120e-02,  1.2996e-02, -2.6592e-02, -6.7008e-02,\n",
      "        -5.3110e-03, -5.3152e-02, -1.2382e-02, -2.5155e-02,  6.2906e-02,\n",
      "        -3.6431e-03,  3.2169e-02, -2.3525e-03, -5.7970e-02, -2.7543e-02,\n",
      "         2.2410e-02,  5.2498e-02, -7.8914e-02,  3.3831e-02,  1.9180e-02,\n",
      "         5.9438e-02, -3.3919e-03, -5.6853e-02, -2.1850e-02,  3.5967e-02,\n",
      "        -3.2165e-02,  2.9354e-02,  3.2136e-02,  6.8325e-02,  4.6689e-02,\n",
      "        -3.0433e-02, -5.4293e-02,  1.3524e-02, -7.6386e-02,  6.9778e-02,\n",
      "        -3.7203e-02,  3.0619e-02, -5.4413e-02,  2.4046e-02, -2.9408e-02,\n",
      "        -6.1521e-02,  4.7457e-02,  8.6323e-02,  6.0270e-02,  1.9007e-02,\n",
      "         2.6040e-02, -8.0867e-02, -7.9848e-02, -6.3313e-02, -4.2896e-02,\n",
      "         3.7731e-02,  6.3440e-02,  5.6629e-02, -1.8709e-02, -2.8880e-02,\n",
      "         4.6257e-02,  4.0577e-03, -4.3933e-02,  3.7559e-02, -1.6444e-02,\n",
      "        -3.7608e-02, -8.4125e-02,  8.0320e-02,  7.2044e-02, -3.4759e-02,\n",
      "         4.2894e-02], requires_grad=True) torch.Size([256])\n",
      "hidden3.weight Parameter containing:\n",
      "tensor([[ 0.0164, -0.0079, -0.0560,  ..., -0.0137, -0.0309,  0.0463],\n",
      "        [ 0.0495,  0.0544, -0.0320,  ..., -0.0012, -0.0093, -0.0195],\n",
      "        [-0.0223,  0.0301,  0.0488,  ..., -0.0597,  0.0143, -0.0335],\n",
      "        ...,\n",
      "        [ 0.0390,  0.0071, -0.0561,  ..., -0.0184,  0.0139,  0.0529],\n",
      "        [ 0.0366, -0.0580, -0.0261,  ...,  0.0588, -0.0006,  0.0139],\n",
      "        [-0.0599,  0.0247, -0.0476,  ..., -0.0588,  0.0456, -0.0021]],\n",
      "       requires_grad=True) torch.Size([512, 256])\n",
      "hidden3.bias Parameter containing:\n",
      "tensor([ 2.3015e-02, -5.9117e-02,  4.3289e-02, -2.5134e-02,  4.7649e-02,\n",
      "         9.6500e-04,  3.6394e-02, -2.8187e-02,  1.7367e-03,  2.2509e-02,\n",
      "        -6.0613e-02,  3.1602e-02, -2.5808e-02,  4.3742e-02, -4.7570e-02,\n",
      "        -1.3132e-02,  2.4014e-02,  4.2256e-02,  4.9815e-02, -5.6990e-02,\n",
      "         9.8920e-03,  1.6724e-02, -1.1685e-02, -1.2659e-02, -5.9269e-02,\n",
      "        -2.0020e-02, -2.1278e-02,  2.8368e-02, -8.6902e-03, -2.2979e-02,\n",
      "        -1.0360e-03,  2.1820e-02, -3.1558e-02,  1.4607e-02, -6.1362e-02,\n",
      "        -5.6662e-02, -1.5238e-02,  5.5036e-03, -3.6549e-02,  4.7957e-02,\n",
      "        -1.5087e-03, -1.2150e-03,  6.6097e-03,  1.1626e-03, -2.0055e-02,\n",
      "         5.4415e-02, -1.8537e-02,  1.1359e-02,  2.4903e-02,  1.8589e-02,\n",
      "         4.8960e-02,  1.6997e-02,  1.2773e-02, -5.7757e-02, -6.1389e-02,\n",
      "         4.1035e-02,  4.8543e-02, -9.6418e-03,  2.1370e-02,  5.2002e-02,\n",
      "        -2.8385e-02,  5.0133e-02, -4.4370e-02, -1.5601e-02,  4.2950e-02,\n",
      "         3.8174e-02, -8.7463e-03, -4.0330e-02, -1.1968e-02, -2.2809e-02,\n",
      "        -2.1208e-02, -3.8455e-03, -2.6893e-02, -1.6802e-02,  8.6026e-04,\n",
      "         3.1590e-02, -5.9684e-02, -4.3710e-02,  4.9105e-02, -2.9184e-02,\n",
      "        -2.0757e-02, -6.1176e-02,  5.8646e-02, -3.5738e-02, -1.9145e-02,\n",
      "         5.7750e-02, -6.1431e-02,  5.1782e-02, -1.9658e-02, -2.1324e-02,\n",
      "        -6.8274e-03,  1.3510e-02, -2.1027e-02, -1.5266e-02,  4.6541e-02,\n",
      "        -1.5343e-02, -1.1033e-02,  1.3954e-02, -5.9848e-02, -4.8009e-02,\n",
      "        -4.4967e-02,  2.5747e-02,  3.2267e-02,  1.1351e-02, -5.1040e-02,\n",
      "         4.6085e-04, -1.0524e-02,  1.2247e-03, -2.2222e-02,  5.3669e-03,\n",
      "        -5.2532e-02, -6.6896e-03, -3.5925e-02, -6.4255e-03,  2.7006e-02,\n",
      "         5.9042e-02, -4.0724e-02, -5.8188e-02,  3.7847e-02,  4.3868e-02,\n",
      "        -4.4747e-03,  2.9835e-02,  4.2399e-02,  9.3474e-04, -2.7399e-02,\n",
      "        -5.0048e-02, -1.8197e-02,  4.7284e-02,  5.5428e-02,  5.7407e-02,\n",
      "        -1.7940e-02,  9.9850e-03, -3.8229e-02,  5.6376e-02, -5.3671e-02,\n",
      "        -3.0954e-02, -2.1740e-02,  5.1897e-02, -6.1114e-02, -4.1445e-02,\n",
      "        -1.0300e-02,  2.2885e-02, -1.7649e-02,  3.1641e-02, -2.5507e-02,\n",
      "         9.8058e-03, -4.9701e-02, -6.1081e-02,  1.9248e-02, -3.9231e-02,\n",
      "        -5.1604e-02, -1.7379e-02, -1.8426e-02, -5.7720e-02, -3.0338e-02,\n",
      "        -3.9733e-02,  2.8620e-02,  5.3662e-02, -7.9901e-03, -5.8180e-02,\n",
      "        -1.7236e-03, -3.6044e-03, -3.1929e-02,  1.3903e-02, -5.5382e-02,\n",
      "         2.7438e-02,  2.0188e-02, -5.7894e-02, -3.3508e-02,  4.8973e-02,\n",
      "         2.1373e-02,  3.0297e-02,  2.0952e-02,  1.1710e-02,  2.5830e-02,\n",
      "        -3.3914e-02,  5.1126e-02, -1.5060e-02, -3.2961e-02, -1.8390e-02,\n",
      "         3.4720e-02, -9.8057e-03,  1.5422e-02, -3.7243e-02, -2.9985e-02,\n",
      "        -4.8509e-02,  4.7664e-02,  5.5624e-02, -6.0646e-02,  5.6883e-02,\n",
      "         3.4420e-02,  2.0076e-02,  2.4278e-02,  4.5485e-02,  4.8852e-02,\n",
      "        -3.9884e-03, -1.8928e-02,  6.7402e-03,  5.7121e-02,  1.3967e-02,\n",
      "        -4.6036e-02, -2.9544e-02, -4.7835e-02, -6.2103e-02,  5.5732e-02,\n",
      "         2.0963e-02, -5.7138e-02, -3.9108e-02, -3.2522e-02, -5.4706e-02,\n",
      "         4.5940e-02,  2.8282e-02,  2.9020e-02, -4.7849e-02,  2.1575e-02,\n",
      "         1.2241e-02,  2.6575e-03,  3.7454e-02, -5.4421e-02,  1.5243e-02,\n",
      "         2.7404e-02, -5.0245e-03,  6.2697e-03, -4.2926e-02, -4.9295e-02,\n",
      "        -2.9137e-02, -5.0738e-02,  8.0651e-03,  2.1817e-02, -5.6642e-02,\n",
      "        -7.7039e-03,  3.2286e-02,  5.6284e-02, -4.2178e-02, -4.0213e-02,\n",
      "         3.2598e-02, -1.3737e-02, -7.4487e-03, -2.9665e-02,  1.6158e-02,\n",
      "         5.1303e-02,  4.1451e-02, -3.6813e-02, -9.3981e-03, -7.2172e-03,\n",
      "        -1.6228e-02,  5.6549e-02,  3.3124e-02, -5.0646e-02, -6.8253e-03,\n",
      "         6.0445e-02,  9.6559e-03, -4.0375e-02, -2.0588e-02, -1.1722e-02,\n",
      "         4.3277e-02, -5.2564e-02,  5.1715e-02,  5.3031e-02,  2.2580e-02,\n",
      "        -1.9595e-02, -5.7005e-02,  2.2428e-02, -1.2683e-02, -3.6307e-02,\n",
      "        -4.0921e-02,  4.4081e-02,  4.2037e-02, -3.8474e-02,  3.3740e-02,\n",
      "        -2.3515e-02, -9.7986e-03,  1.8888e-03,  8.4117e-06,  3.6124e-02,\n",
      "        -2.3277e-02,  3.6229e-02,  3.6523e-02, -4.0344e-03,  4.4453e-02,\n",
      "         5.3070e-02,  6.6179e-04, -6.7882e-03,  1.7653e-02,  4.2702e-02,\n",
      "        -8.7964e-03,  5.2212e-02, -3.1035e-02, -3.6472e-02,  1.8620e-02,\n",
      "         5.8925e-03, -5.8578e-02, -4.2800e-02, -7.3070e-03,  3.3108e-02,\n",
      "         4.1377e-02,  2.4059e-02,  3.3136e-02, -3.5620e-02, -5.6333e-02,\n",
      "         6.0899e-02,  2.3650e-02,  1.3187e-02,  6.2386e-02, -4.2969e-02,\n",
      "        -5.6962e-02,  1.2926e-02,  4.3838e-02,  8.8636e-03,  4.4331e-02,\n",
      "        -5.5431e-02,  3.1796e-02, -1.0355e-02,  3.4298e-02, -3.2753e-02,\n",
      "        -5.4126e-02, -3.3200e-02, -3.3296e-02,  5.4823e-02, -5.5620e-02,\n",
      "        -5.6468e-02, -5.7045e-02,  3.6745e-02, -3.6814e-02,  4.9423e-02,\n",
      "        -3.3455e-03,  5.3639e-02, -1.0155e-02,  2.4957e-02,  3.5776e-03,\n",
      "        -5.8789e-02,  3.5459e-02, -5.3153e-02, -3.4092e-02, -2.1281e-03,\n",
      "        -4.7373e-02,  5.3185e-02,  5.8914e-02, -1.1736e-03, -3.0003e-03,\n",
      "         2.3186e-02,  5.2950e-02,  7.9278e-03, -5.9489e-02,  3.6957e-02,\n",
      "         5.4248e-02,  6.1926e-02,  5.5345e-03, -3.3322e-03, -3.9105e-02,\n",
      "         9.0888e-03,  4.1613e-02,  4.9044e-02,  6.0909e-02,  6.0200e-02,\n",
      "         1.5824e-02, -5.3829e-02,  1.8548e-02, -3.8126e-02, -4.4672e-02,\n",
      "        -2.9560e-02, -8.8553e-03,  2.6374e-02, -5.6425e-02,  1.2490e-02,\n",
      "        -1.1296e-02,  1.1734e-02,  4.2878e-02,  1.9052e-02, -5.7744e-02,\n",
      "         5.0856e-02, -4.2673e-02,  5.1862e-02,  3.9500e-02, -4.2412e-02,\n",
      "         1.4400e-02, -2.3743e-02,  4.2371e-02,  5.1500e-02,  1.9514e-02,\n",
      "        -5.5492e-02, -5.6076e-02, -3.9428e-02, -1.9007e-03,  3.3492e-02,\n",
      "        -5.3321e-02,  1.0580e-02, -9.5361e-03,  2.1183e-02,  6.0494e-02,\n",
      "         2.3821e-02, -3.2176e-02,  5.5250e-02, -4.6487e-02, -2.2306e-02,\n",
      "         2.3838e-02, -5.4084e-02,  3.8405e-02,  4.2438e-02, -3.0770e-03,\n",
      "        -5.9578e-03,  2.4106e-02, -2.3071e-02, -5.4803e-02, -3.6504e-02,\n",
      "         2.2796e-02,  2.0837e-02,  4.6328e-02,  5.0774e-02,  1.2709e-02,\n",
      "         1.7233e-02, -1.0534e-02,  2.6178e-02, -3.0456e-02,  1.0572e-02,\n",
      "        -3.4307e-02, -1.4907e-02,  2.2107e-02,  9.5826e-03, -3.2875e-02,\n",
      "         1.1615e-02, -3.1170e-02, -4.9882e-02,  5.0157e-02,  9.6423e-03,\n",
      "        -5.0971e-02,  4.9600e-02,  1.9195e-02, -1.8641e-02, -2.9203e-02,\n",
      "         1.2511e-02,  3.0966e-02, -5.0084e-02, -2.3737e-02,  4.5217e-02,\n",
      "        -1.5093e-02,  1.9819e-02,  2.7892e-02,  1.1618e-02,  5.4304e-02,\n",
      "        -3.5822e-02, -3.2528e-02, -5.1570e-03,  4.0937e-02,  5.1489e-02,\n",
      "        -2.3782e-02, -3.4777e-02,  4.8046e-02, -2.5670e-02,  4.4118e-02,\n",
      "        -5.9019e-02, -4.1218e-02, -7.1437e-03, -3.1155e-02, -5.1115e-02,\n",
      "        -3.7574e-02, -2.6033e-02,  5.7958e-02, -1.0576e-02, -5.9894e-02,\n",
      "        -2.6510e-02, -6.1955e-02,  5.1735e-02,  1.0352e-02,  1.7313e-02,\n",
      "         2.2823e-02,  1.0125e-02, -3.8805e-02,  3.9647e-02, -5.3282e-03,\n",
      "        -2.5323e-03,  2.3434e-02,  5.1972e-02,  3.8895e-03,  1.8445e-02,\n",
      "        -5.5203e-02, -8.2176e-03, -3.0212e-02, -2.8640e-02,  5.9007e-02,\n",
      "         2.4623e-02, -7.4478e-03,  3.7083e-02,  2.0493e-02, -4.4808e-02,\n",
      "        -3.3681e-02, -1.1775e-02, -1.0399e-02,  3.8704e-02, -6.0874e-02,\n",
      "         6.1275e-02, -4.1270e-02, -1.9372e-02,  4.8572e-02, -5.0673e-03,\n",
      "        -6.1771e-02,  1.1481e-02, -1.6367e-02,  2.3273e-02,  2.3036e-02,\n",
      "         4.6840e-03,  3.7215e-02,  5.2564e-02,  2.7787e-03, -6.0694e-02,\n",
      "         4.0355e-03, -5.1518e-02,  5.2364e-02, -5.2938e-02, -3.9199e-02,\n",
      "         4.2383e-02, -1.8471e-02], requires_grad=True) torch.Size([512])\n",
      "out.weight Parameter containing:\n",
      "tensor([[ 0.0043,  0.0210,  0.0268,  ...,  0.0262, -0.0021, -0.0420],\n",
      "        [-0.0304,  0.0084,  0.0060,  ..., -0.0110, -0.0051,  0.0392],\n",
      "        [ 0.0095, -0.0028,  0.0218,  ...,  0.0063,  0.0181, -0.0247],\n",
      "        ...,\n",
      "        [ 0.0056,  0.0215, -0.0120,  ..., -0.0205,  0.0173, -0.0169],\n",
      "        [ 0.0067, -0.0235, -0.0003,  ...,  0.0273, -0.0074, -0.0151],\n",
      "        [-0.0014, -0.0094, -0.0169,  ...,  0.0089, -0.0053, -0.0092]],\n",
      "       requires_grad=True) torch.Size([10, 512])\n",
      "out.bias Parameter containing:\n",
      "tensor([-0.0363,  0.0413, -0.0029,  0.0091,  0.0418,  0.0212,  0.0359, -0.0008,\n",
      "        -0.0191,  0.0087], requires_grad=True) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in net.named_parameters():\n",
    "    print(name, parameter,parameter.size()) # name是上面定义的hidden1, out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义loss_batch\n",
    "\n",
    "1. 计算batch的loss\n",
    "2. 计算梯度\n",
    "3. 执行更新\n",
    "4. 清空梯度\n",
    "\n",
    "torch.nn.functional 很多层和函数在这里都会见到\n",
    "torch.nn.functional中有很多功能，后续会常用的。那什么时候使用nn.Module，什么时候使用nn.functional呢？一般情况下，如果模型有可学习的参数，最好用nn.Module，其他情况nn.functional相对更简单一些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T02:35:07.694249Z",
     "start_time": "2024-07-21T02:35:07.692372Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T02:35:07.723384Z",
     "start_time": "2024-07-21T02:35:07.721668Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb) \n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward() # 反向传播, 计算所有权重参数的梯度\n",
    "        opt.step() # 计算完梯度后, 更新权重(用到了学习率lr, 优化器)\n",
    "        opt.zero_grad() # pytorch默认累加梯度, 这里每个batch要清零\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 一般在训练模型时加上model.train()，这样会正常使用Batch Normalization和 Dropout\n",
    "- 测试的时候一般选择model.eval()，这样就不会使用Batch Normalization和 Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义fit训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T02:35:07.718906Z",
     "start_time": "2024-07-21T02:35:07.716908Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# fit(训练函数)\n",
    "# steps:epoch\n",
    "def fit(steps, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for step in range(steps): \n",
    "        model.train() # 指定训练模式, 会去更新权重参数\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval() # 指定验证模式, 不更新权重参数\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        print('当前step:'+str(step), '验证集损失：'+str(val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三行搞定！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T02:35:18.891696Z",
     "start_time": "2024-07-21T02:35:07.723950Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前step:0 验证集损失：0.15105897065401078\n",
      "当前step:1 验证集损失：0.09903202782571316\n",
      "当前step:2 验证集损失：0.11829739667475224\n",
      "当前step:3 验证集损失：0.09138807307817041\n",
      "当前step:4 验证集损失：0.08379621616005897\n",
      "当前step:5 验证集损失：0.09629965027086437\n",
      "当前step:6 验证集损失：0.08847701354511082\n",
      "当前step:7 验证集损失：0.08918074439344928\n",
      "当前step:8 验证集损失：0.09357842047550949\n",
      "当前step:9 验证集损失：0.12021851745907043\n",
      "当前step:10 验证集损失：0.10588144704177975\n",
      "当前step:11 验证集损失：0.08904383157739648\n",
      "当前step:12 验证集损失：0.09056842509027628\n",
      "当前step:13 验证集损失：0.09964602646145504\n",
      "当前step:14 验证集损失：0.10899022439019755\n",
      "当前step:15 验证集损失：0.11248470860088709\n",
      "当前step:16 验证集损失：0.10487074372011702\n",
      "当前step:17 验证集损失：0.1020547483243412\n",
      "当前step:18 验证集损失：0.10735056589142186\n",
      "当前step:19 验证集损失：0.11456249356001426\n",
      "当前step:20 验证集损失：0.1109027882561063\n",
      "当前step:21 验证集损失：0.12930115064980627\n",
      "当前step:22 验证集损失：0.13417806550644054\n",
      "当前step:23 验证集损失：0.14738642938625998\n",
      "当前step:24 验证集损失：0.12133957210611393\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(25, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T02:35:18.893775Z",
     "start_time": "2024-07-21T02:35:18.892533Z"
    }
   },
   "source": [
    "# 计算出准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 97.8%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total_instance_num = 0\n",
    "for steps in range(25):\n",
    "    for xb,  yb in valid_dl: \n",
    "        _, predicted = torch.max(model(xb), 1)\n",
    "        total_instance_num += yb.size(0)\n",
    "        correct += (predicted == yb).sum().item()\n",
    "\n",
    "print(\"accuracy is {}%\".format(correct * 100 / total_instance_num ))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
